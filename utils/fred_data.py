import streamlit as st
import pandas as pd
import numpy as np
from fredapi import Fred
from datetime import datetime, timedelta
import io
import time

class FredDataManager:
    def __init__(self):
        # FRED API key
        self.fred_api_key = "b32ddacf51e52ec5af60de1cf34a183b"
        self.fred = None
        self.connection_tested = False
        
        # FRED indicators mapping - ìš”ì²­ëœ ê²½ì œ ì§€í‘œë“¤
        self.indicators = {
            'USD/KRW': 'DEXKOUS',           # USD-KRW í™˜ìœ¨
            'WTI': 'DCOILWTICO',            # êµ­ì œìœ ê°€ (WTI)
            'US10Y': 'DGS10',               # ë¯¸êµ­ 10ë…„ êµ­ì±„ê¸ˆë¦¬
            'CPI': 'CPIAUCSL',              # ë¯¸êµ­ CPI
            'PDI': 'DSPI',                  # ë¯¸êµ­ Personal Disposal Income
            'PPI': 'PPIACO',                # ë¯¸êµ­ PPI
            'UNRATE': 'UNRATE',             # ë¯¸êµ­ ì‹¤ì—…ë¥ 
            'AUTO_SALES': 'TOTALSA',        # ë¯¸êµ­ ìë™ì°¨ íŒë§¤ëŸ‰
            'AUTO_PROD': 'DAUPSA',      # ë¯¸êµ­ ìë™ì°¨ ìƒì‚°ëŸ‰
            'BDI': 'STLFSI2'                # êµ­ì œ ìš´ì„ì§€ìˆ˜ (Baltic Dry Index proxy)
        }
    
    def test_fred_connection(self):
        """FRED API ì—°ê²° í…ŒìŠ¤íŠ¸"""
        try:
            st.info("ğŸ”— FRED API ì—°ê²°ì„ í…ŒìŠ¤íŠ¸í•˜ëŠ” ì¤‘...")
            self.fred = Fred(api_key=self.fred_api_key)
            
            # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ (GDP ë°ì´í„° ìµœì‹  1ê°œ)
            test_data = self.fred.get_series('GDP', limit=1)
            
            if test_data is not None and len(test_data) > 0:
                st.success("âœ… FRED API ì—°ê²° ì„±ê³µ!")
                self.connection_tested = True
                return True
            else:
                st.error("âŒ FRED API ì—°ê²° ì‹¤íŒ¨: ë°ì´í„°ë¥¼ ë°›ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                return False
                
        except Exception as e:
            st.error(f"âŒ FRED API ì—°ê²° ì˜¤ë¥˜: {str(e)}")
            st.error("API í‚¤ë¥¼ í™•ì¸í•˜ê±°ë‚˜ ì¸í„°ë„· ì—°ê²°ì„ í™•ì¸í•´ì£¼ì„¸ìš”")
            return False
    
    def _fetch_series_data(self, series_id, series_name, start_date, end_date):
        """ê°œë³„ ì‹œë¦¬ì¦ˆ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
        try:
            # ë‚ ì§œë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
            start_str = start_date.strftime('%Y-%m-%d')
            end_str = end_date.strftime('%Y-%m-%d')
            
            st.write(f"ğŸ” {series_name} ë°ì´í„° ìš”ì²­: {start_str} ~ {end_str}")
            
            series_data = self.fred.get_series(
                series_id,
                start=start_str,
                end=end_str
            )
            
            if series_data is not None and len(series_data) > 0:
                # ìš”ì²­í•œ ê¸°ê°„ìœ¼ë¡œ í•„í„°ë§
                series_data = series_data.loc[start_date:end_date]
                
                # ì›”ë³„ ë°ì´í„°ë¡œ ë¦¬ìƒ˜í”Œë§
                series_data = series_data.resample('M').last().dropna()
                
                if len(series_data) > 0:
                    actual_start = series_data.index.min().strftime('%Y-%m-%d')
                    actual_end = series_data.index.max().strftime('%Y-%m-%d')
                    st.write(f"âœ… {series_name} ì‹¤ì œ ë°ì´í„°: {actual_start} ~ {actual_end} ({len(series_data)}ê°œ)")
                    return series_data
                else:
                    st.warning(f"âš ï¸ {series_name}: ìš”ì²­ ê¸°ê°„ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
                    return None
            else:
                st.warning(f"âš ï¸ {series_name}: FREDì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                return None
                
        except Exception as e:
            st.error(f"âŒ {series_name} ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            return None
    
    def load_fred_data(self, start_date=None, end_date=None):
        """Load all FRED economic indicators with user-specified date range"""
        # ê¸°ë³¸ê°’ ì„¤ì • (ìµœê·¼ 10ë…„)
        if end_date is None:
            end_date = datetime.now()
        if start_date is None:
            start_date = end_date - timedelta(days=10*365)
        
        # API ì—°ê²° í…ŒìŠ¤íŠ¸
        if not self.connection_tested:
            if not self.test_fred_connection():
                raise Exception("FRED API ì—°ê²°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤")
        
        try:
            st.info(f"ğŸ“… **ìš”ì²­ ë°ì´í„° ìˆ˜ì§‘ ê¸°ê°„: {start_date.strftime('%Y-%m-%d')} ~ {end_date.strftime('%Y-%m-%d')}**")
            
            data_dict = {}
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            total_indicators = len(self.indicators)
            
            for idx, (name, series_id) in enumerate(self.indicators.items()):
                progress = (idx + 1) / total_indicators
                progress_bar.progress(progress)
                status_text.text(f"ğŸ“Š {name} ë°ì´í„° ë¡œë”© ì¤‘... ({idx + 1}/{total_indicators})")
                
                # ê°œë³„ ì‹œë¦¬ì¦ˆ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
                series_data = self._fetch_series_data(series_id, name, start_date, end_date)
                
                if series_data is not None and len(series_data) > 0:
                    data_dict[name] = series_data
                
                # API í˜¸ì¶œ ê°„ê²© ì¡°ì •
                time.sleep(0.3)
            
            progress_bar.progress(1.0)
            status_text.text("âœ… ëª¨ë“  ë°ì´í„° ë¡œë”© ì™„ë£Œ!")
            
            if not data_dict:
                raise Exception("ìš”ì²­í•œ ê¸°ê°„ì— ì‚¬ìš© ê°€ëŠ¥í•œ FRED ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
            
            st.success(f"ğŸ“Š ì„±ê³µì ìœ¼ë¡œ ë¡œë“œëœ ì§€í‘œ: {len(data_dict)}ê°œ")
            
            # Combine all series into a DataFrame
            fred_df = pd.DataFrame(data_dict)
            
            # ì¸ë±ìŠ¤ë¥¼ ì›”ë§ë¡œ í†µì¼
            fred_df.index = fred_df.index.to_period('M').to_timestamp('M')
            
            # ì‚¬ìš©ìê°€ ì„ íƒí•œ ê¸°ê°„ìœ¼ë¡œ ë‹¤ì‹œ í•œë²ˆ í•„í„°ë§ (í™•ì‹¤íˆ í•˜ê¸° ìœ„í•´)
            mask = (fred_df.index >= start_date) & (fred_df.index <= end_date)
            fred_df = fred_df.loc[mask]
            
            # Forward fill missing values
            fred_df = fred_df.fillna(method='ffill')
            
            # Calculate PDI/CPI ratio if both are available
            if 'PDI' in fred_df.columns and 'CPI' in fred_df.columns:
                # CPIë¥¼ 100ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ì •ê·œí™” (CPIëŠ” ë³´í†µ 100 ê¸°ì¤€)
                fred_df['PDI/CPI'] = (fred_df['PDI'] / (fred_df['CPI'] / 100))
                st.success("âœ… PDI/CPI ë¹„ìœ¨ ê³„ì‚° ì™„ë£Œ")
            
            # Calculate percentage changes for some indicators
            pct_change_indicators = ['USD/KRW', 'WTI', 'CPI', 'PPI']
            for indicator in pct_change_indicators:
                if indicator in fred_df.columns:
                    fred_df[f'{indicator}_pct'] = fred_df[indicator].pct_change() * 100
            
            # ìµœì¢… ë°ì´í„° ê¸°ê°„ í™•ì¸
            if len(fred_df) > 0:
                final_start = fred_df.index.min()
                final_end = fred_df.index.max()
                
                # ë°ì´í„° í’ˆì§ˆ ì²´í¬
                st.subheader("ğŸ“Š ë°ì´í„° ë¡œë”© ê²°ê³¼")
                
                # ìš”ì²­ vs ì‹¤ì œ ë°ì´í„° ê¸°ê°„ ë¹„êµ
                col1, col2 = st.columns(2)
                
                with col1:
                    st.info(f"""
                    **ğŸ“… ìš”ì²­í•œ ê¸°ê°„:**
                    - ì‹œì‘: {start_date.strftime('%Y-%m-%d')}
                    - ì¢…ë£Œ: {end_date.strftime('%Y-%m-%d')}
                    - ê¸°ê°„: {(end_date - start_date).days}ì¼
                    """)
                
                with col2:
                    st.success(f"""
                    **ğŸ“ˆ ì‹¤ì œ ë°ì´í„° ê¸°ê°„:**
                    - ì‹œì‘: {final_start.strftime('%Y-%m-%d')}
                    - ì¢…ë£Œ: {final_end.strftime('%Y-%m-%d')}
                    - í¬ì¸íŠ¸: {len(fred_df)}ê°œì›”
                    """)
                
                # ë°ì´í„° ìš”ì•½ í†µê³„
                summary_col1, summary_col2, summary_col3, summary_col4 = st.columns(4)
                
                with summary_col1:
                    st.metric("ì´ ì§€í‘œ ìˆ˜", len(fred_df.columns))
                with summary_col2:
                    st.metric("ë°ì´í„° í¬ì¸íŠ¸", len(fred_df))
                with summary_col3:
                    coverage_pct = (len(fred_df) / ((end_date.year - start_date.year) * 12 + (end_date.month - start_date.month) + 1)) * 100
                    st.metric("ê¸°ê°„ ì»¤ë²„ë¦¬ì§€", f"{coverage_pct:.1f}%")
                with summary_col4:
                    complete_rows = len(fred_df.dropna())
                    completeness = (complete_rows / len(fred_df)) * 100 if len(fred_df) > 0 else 0
                    st.metric("ë°ì´í„° ì™„ì„±ë„", f"{completeness:.1f}%")
                
                # ìµœì‹  ë°ì´í„° í‘œì‹œ
                st.subheader("ğŸ“ˆ ìµœì‹  ë°ì´í„° (ìµœê·¼ 5ê°œì›”)")
                latest_data = fred_df.tail(5)
                st.dataframe(latest_data, use_container_width=True)
                
                # ëˆ„ë½ ë°ì´í„° ì²´í¬
                missing_data = fred_df.isnull().sum()
                if missing_data.sum() > 0:
                    st.warning("âš ï¸ ì¼ë¶€ ì§€í‘œì— ëˆ„ë½ ë°ì´í„°ê°€ ìˆìŠµë‹ˆë‹¤:")
                    missing_df = pd.DataFrame({
                        'ì§€í‘œ': missing_data.index,
                        'ëˆ„ë½ ê°œìˆ˜': missing_data.values,
                        'ëˆ„ë½ ë¹„ìœ¨(%)': (missing_data.values / len(fred_df) * 100).round(1)
                    })
                    missing_df = missing_df[missing_df['ëˆ„ë½ ê°œìˆ˜'] > 0]
                    st.dataframe(missing_df, use_container_width=True)
                else:
                    st.success("âœ… ëª¨ë“  ë°ì´í„°ê°€ ì™„ì „í•©ë‹ˆë‹¤!")
                
                # ê° ì§€í‘œë³„ ìµœì‹  ê°’ í‘œì‹œ
                st.subheader("ğŸ“Š ê° ì§€í‘œë³„ ìµœì‹  ê°’")
                latest_values = fred_df.iloc[-1]
                
                cols = st.columns(3)
                for idx, (indicator, value) in enumerate(latest_values.items()):
                    col_idx = idx % 3
                    with cols[col_idx]:
                        if pd.notna(value):
                            # í¼ì„¼íŠ¸ ì§€í‘œëŠ” ë‹¤ë¥´ê²Œ í‘œì‹œ
                            if '_pct' in indicator:
                                st.metric(indicator, f"{value:.2f}%")
                            elif indicator == 'UNRATE':
                                st.metric(indicator, f"{value:.1f}%")
                            elif indicator in ['USD/KRW', 'WTI', 'US10Y']:
                                st.metric(indicator, f"{value:.2f}")
                            else:
                                st.metric(indicator, f"{value:,.1f}")
                        else:
                            st.metric(indicator, "N/A")
                
                st.success(f"ğŸ‰ ì´ {len(fred_df.columns)}ê°œ ì§€í‘œ ë¡œë“œ ì™„ë£Œ!")
                
            else:
                st.error("âŒ ìš”ì²­í•œ ê¸°ê°„ì— ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
                st.info("ë‹¤ë¥¸ ê¸°ê°„ì„ ì„ íƒí•´ë³´ì„¸ìš”")
            
            # ì§„í–‰ë¥  ë°”ì™€ ìƒíƒœ í…ìŠ¤íŠ¸ ì œê±°
            progress_bar.empty()
            status_text.empty()
            
            return fred_df
            
        except Exception as e:
            raise Exception(f"FRED ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
    
    def get_indicator_info(self):
        """ê²½ì œ ì§€í‘œ ì •ë³´ ë°˜í™˜"""
        indicator_info = {
            'USD/KRW': {'name': 'ë‹¬ëŸ¬-ì› í™˜ìœ¨', 'description': 'í•œêµ­ ìˆ˜ì¶œì— ì§ì ‘ì  ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” í™˜ìœ¨'},
            'WTI': {'name': 'ì„œë¶€í…ì‚¬ìŠ¤ìœ  ê°€ê²©', 'description': 'êµ­ì œ ìœ ê°€ ì§€í‘œ'},
            'US10Y': {'name': 'ë¯¸êµ­ 10ë…„ êµ­ì±„ê¸ˆë¦¬', 'description': 'ê¸€ë¡œë²Œ ê¸ˆë¦¬ ê¸°ì¤€'},
            'CPI': {'name': 'ë¯¸êµ­ ì†Œë¹„ìë¬¼ê°€ì§€ìˆ˜', 'description': 'ì¸í”Œë ˆì´ì…˜ ì§€í‘œ'},
            'PDI': {'name': 'ë¯¸êµ­ ê°œì¸ê°€ì²˜ë¶„ì†Œë“', 'description': 'ì†Œë¹„ë ¥ ì§€í‘œ'},
            'PPI': {'name': 'ë¯¸êµ­ ìƒì‚°ìë¬¼ê°€ì§€ìˆ˜', 'description': 'ìƒì‚°ë¹„ìš© ì§€í‘œ'},
            'UNRATE': {'name': 'ë¯¸êµ­ ì‹¤ì—…ë¥ ', 'description': 'ê²½ê¸° ìƒí™© ì§€í‘œ'},
            'AUTO_SALES': {'name': 'ë¯¸êµ­ ìë™ì°¨ íŒë§¤ëŸ‰', 'description': 'ì†Œë¹„ ì‹¬ë¦¬ ì§€í‘œ'},
            'AUTO_PROD': {'name': 'ë¯¸êµ­ ìë™ì°¨ ìƒì‚°ëŸ‰', 'description': 'ì œì¡°ì—… í™œë™ ì§€í‘œ'},
            'BDI': {'name': 'êµ­ì œ ìš´ì„ì§€ìˆ˜', 'description': 'ê¸€ë¡œë²Œ ë¬´ì—­ëŸ‰ ì§€í‘œ'},
            'PDI/CPI': {'name': 'ì‹¤ì§ˆ êµ¬ë§¤ë ¥ ì§€í‘œ', 'description': 'PDIë¥¼ CPIë¡œ ë‚˜ëˆˆ ì‹¤ì§ˆ ì†Œë“ ì§€í‘œ'}
        }
        return indicator_info
    
    def process_export_data(self, uploaded_file, analysis_start_date=None, analysis_end_date=None):
        """Process uploaded Excel file containing export sales data with analysis period filtering"""
        try:
            # Read Excel file
            if uploaded_file.name.endswith('.xlsx'):
                df = pd.read_excel(uploaded_file, engine='openpyxl')
            else:
                df = pd.read_excel(uploaded_file)
            
            st.info(f"ğŸ“ íŒŒì¼ ì½ê¸° ì™„ë£Œ: {len(df)}í–‰ x {len(df.columns)}ì—´")
            
            # ì»¬ëŸ¼ ì •ë³´ í‘œì‹œ
            st.subheader("ğŸ“‹ íŒŒì¼ ì»¬ëŸ¼ ì •ë³´")
            for i, col in enumerate(df.columns):
                st.text(f"{i+1}. {col}")
            
            # Try to identify date and sales columns
            date_columns = []
            sales_columns = []
            
            for col in df.columns:
                col_lower = str(col).lower()
                
                # Look for date columns
                if any(word in col_lower for word in ['date', 'time', 'month', 'year', 'period', 'ë‚ ì§œ', 'ì—°ì›”']):
                    date_columns.append(col)
                
                # Look for sales/revenue columns
                if any(word in col_lower for word in ['sales', 'revenue', 'export', 'amount', 'value', 'ë§¤ì¶œ', 'ìˆ˜ì¶œ', 'íŒë§¤']):
                    sales_columns.append(col)
            
            # If no clear columns found, use first two columns
            if not date_columns and not sales_columns:
                if len(df.columns) >= 2:
                    date_columns = [df.columns[0]]
                    sales_columns = [df.columns[1]]
                else:
                    raise Exception("ì—…ë¡œë“œëœ íŒŒì¼ì—ì„œ ë‚ ì§œì™€ ë§¤ì¶œ ì»¬ëŸ¼ì„ ì‹ë³„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            
            # Use the first identified columns
            date_col = date_columns[0] if date_columns else df.columns[0]
            sales_col = sales_columns[0] if sales_columns else df.columns[1]
            
            st.info(f"ğŸ“… ë‚ ì§œ ì»¬ëŸ¼: {date_col}")
            st.info(f"ğŸ’° ë§¤ì¶œ ì»¬ëŸ¼: {sales_col}")
            
            # ìƒ˜í”Œ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
            st.subheader("ğŸ‘€ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°")
            st.dataframe(df[[date_col, sales_col]].head(10))
            
            # Create clean DataFrame
            export_df = pd.DataFrame({
                'Date': pd.to_datetime(df[date_col], errors='coerce'),
                'Export_Sales': pd.to_numeric(df[sales_col], errors='coerce')
            })
            
            # Remove rows with missing values
            before_count = len(export_df)
            export_df = export_df.dropna()
            after_count = len(export_df)
            
            if before_count != after_count:
                st.warning(f"âš ï¸ {before_count - after_count}ê°œ í–‰ì´ ëˆ„ë½ ë°ì´í„°ë¡œ ì¸í•´ ì œê±°ë˜ì—ˆìŠµë‹ˆë‹¤")
            
            # Set date as index and convert to monthly frequency
            export_df = export_df.set_index('Date')
            export_df = export_df.resample('M').sum()  # Sum if multiple entries per month
            
            # Remove zero or negative values
            before_filter = len(export_df)
            export_df = export_df[export_df['Export_Sales'] > 0]
            after_filter = len(export_df)
            
            if before_filter != after_filter:
                st.warning(f"âš ï¸ {before_filter - after_filter}ê°œ í–‰ì´ 0 ì´í•˜ ê°’ìœ¼ë¡œ ì¸í•´ ì œê±°ë˜ì—ˆìŠµë‹ˆë‹¤")
            
            # ë¶„ì„ ê¸°ê°„ í•„í„°ë§ ì ìš©
            if analysis_start_date is not None and analysis_end_date is not None:
                # ë‚ ì§œë¥¼ ì›” ì‹œì‘ì¼ë¡œ ë³€í™˜
                start_filter = pd.Timestamp(analysis_start_date.year, analysis_start_date.month, 1)
                end_filter = pd.Timestamp(analysis_end_date.year, analysis_end_date.month, 1)
                
                st.info(f"ğŸ“… **ì„ íƒëœ ë¶„ì„ ê¸°ê°„ìœ¼ë¡œ í•„í„°ë§: {start_filter.strftime('%Y-%m')} ~ {end_filter.strftime('%Y-%m')}**")
                
                # ì›ë³¸ ë°ì´í„° ê¸°ê°„ í‘œì‹œ
                original_start = export_df.index.min()
                original_end = export_df.index.max()
                st.info(f"ğŸ“Š ì›ë³¸ ë°ì´í„° ê¸°ê°„: {original_start.strftime('%Y-%m')} ~ {original_end.strftime('%Y-%m')}")
                
                # ê¸°ê°„ í•„í„°ë§
                before_period_filter = len(export_df)
                export_df = export_df.loc[start_filter:end_filter]
                after_period_filter = len(export_df)
                
                if after_period_filter < before_period_filter:
                    filtered_count = before_period_filter - after_period_filter
                    st.success(f"âœ… ë¶„ì„ ê¸°ê°„ í•„í„°ë§ ì™„ë£Œ: {filtered_count}ê°œ ë°ì´í„° í¬ì¸íŠ¸ ì œì™¸")
                
                # í•„í„°ë§ í›„ ë°ì´í„° ê¸°ê°„ í™•ì¸
                if len(export_df) > 0:
                    filtered_start = export_df.index.min()
                    filtered_end = export_df.index.max()
                    st.success(f"ğŸ“ˆ **í•„í„°ë§ëœ ë°ì´í„° ê¸°ê°„: {filtered_start.strftime('%Y-%m')} ~ {filtered_end.strftime('%Y-%m')}**")
                else:
                    st.error("âŒ ì„ íƒëœ ë¶„ì„ ê¸°ê°„ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
                    st.info("ë‹¤ë¥¸ ë¶„ì„ ê¸°ê°„ì„ ì„ íƒí•˜ê±°ë‚˜ ë°ì´í„°ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”")
                    return None
            
            if len(export_df) == 0:
                raise Exception("ì²˜ë¦¬ í›„ ìœ íš¨í•œ ìˆ˜ì¶œ ë§¤ì¶œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
            
            # ìµœì¢… ê²°ê³¼ í‘œì‹œ
            st.success(f"âœ… ìˆ˜ì¶œ ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ: {len(export_df)}ê°œ ë°ì´í„° í¬ì¸íŠ¸")
            
            if analysis_start_date is not None and analysis_end_date is not None:
                st.info(f"ğŸ“… **ìµœì¢… ë¶„ì„ ë°ì´í„° ê¸°ê°„: {export_df.index.min().strftime('%Y-%m')} ~ {export_df.index.max().strftime('%Y-%m')}**")
            else:
                st.info(f"ğŸ“… ë°ì´í„° ê¸°ê°„: {export_df.index.min().strftime('%Y-%m')} ~ {export_df.index.max().strftime('%Y-%m')}")
            
            # ë°ì´í„° ìš”ì•½ í†µê³„
            st.subheader("ğŸ“Š ì²˜ë¦¬ëœ ë°ì´í„° ìš”ì•½")
            summary_col1, summary_col2, summary_col3, summary_col4 = st.columns(4)
            
            with summary_col1:
                st.metric("ì´ ë°ì´í„° í¬ì¸íŠ¸", len(export_df))
            with summary_col2:
                st.metric("í‰ê·  ë§¤ì¶œ", f"{export_df['Export_Sales'].mean():,.0f}")
            with summary_col3:
                st.metric("ìµœëŒ€ ë§¤ì¶œ", f"{export_df['Export_Sales'].max():,.0f}")
            with summary_col4:
                st.metric("ìµœì†Œ ë§¤ì¶œ", f"{export_df['Export_Sales'].min():,.0f}")
            
            return export_df
            
        except Exception as e:
            raise Exception(f"ìˆ˜ì¶œ ë°ì´í„° ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
    
    def align_datasets(self, fred_data, export_data):
        """Align FRED and export data by date"""
        try:
            # Find common date range
            start_date = max(fred_data.index.min(), export_data.index.min())
            end_date = min(fred_data.index.max(), export_data.index.max())
            
            st.info(f"ğŸ“… ê³µí†µ ë°ì´í„° ê¸°ê°„: {start_date.strftime('%Y-%m')} ~ {end_date.strftime('%Y-%m')}")
            
            # Filter both datasets to common range
            fred_aligned = fred_data.loc[start_date:end_date]
            export_aligned = export_data.loc[start_date:end_date]
            
            # Combine datasets
            combined_data = pd.concat([fred_aligned, export_aligned], axis=1)
            
            # Drop rows with any missing values
            before_dropna = len(combined_data)
            combined_data = combined_data.dropna()
            after_dropna = len(combined_data)
            
            if before_dropna != after_dropna:
                st.warning(f"âš ï¸ {before_dropna - after_dropna}ê°œ í–‰ì´ ëˆ„ë½ ë°ì´í„°ë¡œ ì¸í•´ ì œê±°ë˜ì—ˆìŠµë‹ˆë‹¤")
            
            if len(combined_data) == 0:
                raise Exception("FRED ë°ì´í„°ì™€ ìˆ˜ì¶œ ë°ì´í„° ê°„ ê²¹ì¹˜ëŠ” ê¸°ê°„ì´ ì—†ìŠµë‹ˆë‹¤")
            
            st.success(f"âœ… ë°ì´í„° ì •ë ¬ ì™„ë£Œ: {len(combined_data)}ê°œ ë°ì´í„° í¬ì¸íŠ¸")
            return combined_data
            
        except Exception as e:
            raise Exception(f"ë°ì´í„° ì •ë ¬ ì‹¤íŒ¨: {str(e)}")
